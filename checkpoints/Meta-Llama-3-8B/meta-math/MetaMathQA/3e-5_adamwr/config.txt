--model_name_or_path meta-llama/Meta-Llama-3-8B --output_dir /home/yjw5427/translora/checkpoints/Meta-Llama-3-8B/meta-math/MetaMathQA/3e-5_adamwr --dataset_name meta-math/MetaMathQA --dataset_config_name default --per_device_train_batch_size 2 --per_device_eval_batch_size 8 --max_steps 1000 --overwrite_output_dir --do_train True --do_eval --seed 42 --dataloader_num_workers 16 --disable_tqdm False --save_strategy no --evaluation_strategy epoch --load_best_model_at_end True --learning_rate 3e-5 --optim_notes adamwr --split_strategy iid --num_rounds 1 --num_clients 1 --sample_clients 1 --max_gate_samples 50 --max_train_samples 100000 --gradient_accumulation_steps 4
