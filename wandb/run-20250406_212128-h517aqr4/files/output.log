
















































































































/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f329b5-1da986a53cc5ead15fff4668;953f2736-9819-43a4-b8f5-3fbdacdccfbf)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
{'train_runtime': 286.2376, 'train_samples_per_second': 3.158, 'train_steps_per_second': 0.395, 'train_loss': 2.1206746059181416, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               = 14832235GF
  train_loss               =     2.1207
  train_runtime            = 0:04:46.23
  train_samples            =       1585
  train_samples_per_second =      3.158
  train_steps_per_second   =      0.395
179
1.2e-06


















































































































































































 99%|████████████████████████████████████████████████████████████████████████████████████████████████▍| 178/179 [07:22<00:02,  2.48s/it]
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f32b73-04c046e04a09733c20b370e4;4e6da930-092d-4c4f-b630-11987a94b50d)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
  0%|                                                                                                           | 0/286 [00:00<?, ?it/s]
***** train metrics *****
  epoch                    =        1.0
  total_flos               = 23495310GF
  train_loss               =     0.8236
  train_runtime            = 0:07:24.69
  train_samples            =       2512
  train_samples_per_second =       3.22
  train_steps_per_second   =      0.403
286





























































































































































































































































































100%|████████████████████████████████████████████████████████████████████████████████████████████████▋| 285/286 [11:47<00:02,  2.48s/it]
{'train_runtime': 710.3944, 'train_samples_per_second': 3.221, 'train_steps_per_second': 0.403, 'train_loss': 2.032474117679196, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               = 37539993GF
  train_loss               =     2.0325
  train_runtime            = 0:11:50.39
  train_samples            =       4013
  train_samples_per_second =      3.221
  train_steps_per_second   =      0.403
38
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f32e3b-2de8b43b4b5faf3b5ef3d128;a2ff489b-fa29-4c87-8d73-c78aa22ef816)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(





































 97%|████████████████████████████████████████████████████████████████████████████████████████████████▍  | 37/38 [01:32<00:02,  2.49s/it]
{'train_runtime': 94.5469, 'train_samples_per_second': 3.215, 'train_steps_per_second': 0.402, 'train_loss': 4.2265881990131575, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               =  4987831GF
  train_loss               =     4.2266
  train_runtime            = 0:01:34.54
  train_samples            =        540
  train_samples_per_second =      3.215
  train_steps_per_second   =      0.402
5
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f32e9b-5d48687e49f17b53034256b0;e6bffcf7-81dd-4e93-acf1-0415fdf5d9b7)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(





100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:12<00:00,  2.49s/it]
{'train_runtime': 12.4999, 'train_samples_per_second': 3.2, 'train_steps_per_second': 0.4, 'train_loss': 5.360546875, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               =   656293GF
  train_loss               =     5.3605
  train_runtime            = 0:00:12.49
  train_samples            =         83
  train_samples_per_second =        3.2
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f32ea8-265de5394e6b9fdc0d02b255;40c6690d-cb70-4315-b8d0-d0587c50254a)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(




 80%|███████████████████████████████████████████████████████████████████████████████▏                   | 12/15 [00:08<00:02,  1.38it/s]
***** eval metrics *****
  epoch                   =        1.0
  eval_accuracy           =        0.0
  eval_loss               =     2.6231
  eval_runtime            = 0:00:10.63
  eval_samples            =        116
  eval_samples_per_second =     10.907
  eval_steps_per_second   =       1.41
  perplexity              =     13.779
This round clients: [5, 6, 7, 8, 9]
113

100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:09<00:00,  1.61it/s]
















































































































/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f32fcd-067c0492465883f45e0924dd;45eb8dfd-8fc8-487a-92ea-58fd1f965869)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
{'train_runtime': 280.4629, 'train_samples_per_second': 3.223, 'train_steps_per_second': 0.403, 'train_loss': 1.3316774621474003, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               = 14832235GF
  train_loss               =     1.3317
  train_runtime            = 0:04:40.46
  train_samples            =       1585
  train_samples_per_second =      3.223
  train_steps_per_second   =      0.403
179
1.8000000000000001e-06


















































































































































































/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f3318b-2374d01500f974bc137de5b2;9108dfc5-4f45-4c4d-960a-5cf05c94dec6)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
{'train_runtime': 444.7884, 'train_samples_per_second': 3.22, 'train_steps_per_second': 0.402, 'train_loss': 0.8255226518854749, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               = 23495310GF
  train_loss               =     0.8255
  train_runtime            = 0:07:24.78
  train_samples            =       2512
  train_samples_per_second =       3.22
  train_steps_per_second   =      0.402
286
1.8000000000000001e-06





























































































































































































































































































/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f33454-5e7a5b4654a0a513621493b6;c479bd29-96f0-422b-afcc-ecd4dda7eff1)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
  0%|                                                                                                            | 0/38 [00:00<?, ?it/s]
{'train_runtime': 711.2235, 'train_samples_per_second': 3.217, 'train_steps_per_second': 0.402, 'train_loss': 0.7256691139061134, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               = 37539993GF
  train_loss               =     0.7257
  train_runtime            = 0:11:51.22
  train_samples            =       4013
  train_samples_per_second =      3.217
  train_steps_per_second   =      0.402
38





































 97%|████████████████████████████████████████████████████████████████████████████████████████████████▍  | 37/38 [01:32<00:02,  2.49s/it]
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f334b4-4b4a387568537ea179908c5a;5a89987e-1bc3-4101-8ffa-8963bb3a11a8)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
***** train metrics *****
  epoch                    =        1.0
  total_flos               =  4987831GF
  train_loss               =     2.7461
  train_runtime            = 0:01:34.80
  train_samples            =        540
  train_samples_per_second =      3.207
  train_steps_per_second   =      0.401
5
1.8000000000000001e-06




 80%|████████████████████████████████████████████████████████████████████████████████▊                    | 4/5 [00:10<00:02,  2.49s/it]
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f334c2-24ba6c697c4408310178855c;173a038c-9998-4d8c-b1cd-64b2769e3473)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
***** train metrics *****
  epoch                    =        1.0
  total_flos               =   656293GF
  train_loss               =     2.9598
  train_runtime            = 0:00:12.51
  train_samples            =         83
  train_samples_per_second =      3.196
  train_steps_per_second   =      0.399




 87%|█████████████████████████████████████████████████████████████████████████████████████▊             | 13/15 [00:08<00:01,  1.38it/s]
***** eval metrics *****
  epoch                   =        1.0
  eval_accuracy           =     0.0776
  eval_loss               =     1.8806
  eval_runtime            = 0:00:10.60
  eval_samples            =        116
  eval_samples_per_second =     10.941
  eval_steps_per_second   =      1.415
  perplexity              =     6.5574
This round clients: [5, 6, 7, 8, 9]
113
100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:09<00:00,  1.62it/s]
















































































































/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f335e7-589f1a78387c4ec85db91f9c;331d50ec-8998-48e0-91e7-dcf179736c84)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
{'train_runtime': 280.5114, 'train_samples_per_second': 3.223, 'train_steps_per_second': 0.403, 'train_loss': 1.076889173119469, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               = 14832235GF
  train_loss               =     1.0769
  train_runtime            = 0:04:40.51
  train_samples            =       1585
  train_samples_per_second =      3.223
  train_steps_per_second   =      0.403
179
2.4e-06


















































































































































































/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f337a5-11d561586a1b83f272912de8;18fef3a9-823d-4289-b846-7b18ac0f3c60)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
{'train_runtime': 445.1791, 'train_samples_per_second': 3.217, 'train_steps_per_second': 0.402, 'train_loss': 0.8312302914411662, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               = 23495310GF
  train_loss               =     0.8312
  train_runtime            = 0:07:25.17
  train_samples            =       2512
  train_samples_per_second =      3.217
  train_steps_per_second   =      0.402
286
2.4e-06





























































































































































































































































































/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f33a6d-5fc3149112b8d3e074e20541;b77da7ec-ce9d-4333-b779-9125860e6824)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
{'train_runtime': 710.8246, 'train_samples_per_second': 3.219, 'train_steps_per_second': 0.402, 'train_loss': 0.5471372804441652, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               = 37539993GF
  train_loss               =     0.5471
  train_runtime            = 0:11:50.82
  train_samples            =       4013
  train_samples_per_second =      3.219
  train_steps_per_second   =      0.402
38
2.4e-06























  File "/data/home/yjw5427/translora/fed_lora_cls.py", line 857, in <module>                            | 23/38 [00:57<00:37,  2.49s/it]
    main()
  File "/data/home/yjw5427/translora/fed_lora_cls.py", line 735, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/trainer.py", line 2388, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/trainer.py", line 3518, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/accelerate/accelerator.py", line 2241, in backward
    loss.backward(**kwargs)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in backward
    _engine_run_backward(
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/torch/autograd/graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "/data/home/yjw5427/translora/fed_lora_cls.py", line 857, in <module>
    main()
  File "/data/home/yjw5427/translora/fed_lora_cls.py", line 735, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/trainer.py", line 2388, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/trainer.py", line 3518, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/accelerate/accelerator.py", line 2241, in backward
    loss.backward(**kwargs)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in backward
    _engine_run_backward(
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/torch/autograd/graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt