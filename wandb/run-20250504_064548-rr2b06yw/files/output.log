05/04/2025 06:45:49 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[WARNING|logging.py:314] 2025-05-04 06:45:59,424 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
flash_attention_2
Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.10it/s]
Model dtype: torch.bfloat16
Number of layers (parameter sets) in the model: 291
max_gate_samples is 50
trainable params: 29,360,128 || all params: 8,059,621,376 || trainable%: 0.3643
['query', 'response', 'type', 'original_question']
  0%|                                                                                                                                                                                  | 0/1 [00:00<?, ?it/s][WARNING|logging.py:329] 2025-05-04 06:46:26,572 >> `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
==========================================
True
==========================================
=================================================================================
Adamw
8
False
=================================================================================
=================================================================================
SchedulerType.COSINE
=================================================================================
checkpoint
None
/root/miniconda3/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
                                                                                                                                                                                                             
                                                                                                                                                                                                             
{'loss': 1.2739, 'learning_rate': 5e-06, 'epoch': 0.0}
{'loss': 1.2746, 'learning_rate': 1e-05, 'epoch': 0.01}
{'loss': 1.2713, 'learning_rate': 1.5e-05, 'epoch': 0.01}
{'loss': 1.2668, 'learning_rate': 2e-05, 'epoch': 0.01}
{'loss': 1.2283, 'learning_rate': 2.5e-05, 'epoch': 0.02}
{'loss': 1.2056, 'learning_rate': 3e-05, 'epoch': 0.02}
{'loss': 1.1819, 'learning_rate': 3.5e-05, 'epoch': 0.03}
{'loss': 1.1598, 'learning_rate': 4e-05, 'epoch': 0.03}
{'loss': 1.0936, 'learning_rate': 4.5e-05, 'epoch': 0.03}
{'loss': 1.0292, 'learning_rate': 5e-05, 'epoch': 0.04}
{'loss': 0.9509, 'learning_rate': 4.9996582624811725e-05, 'epoch': 0.04}
{'loss': 0.8561, 'learning_rate': 4.9986331433523156e-05, 'epoch': 0.04}
{'loss': 0.8276, 'learning_rate': 4.996924922870762e-05, 'epoch': 0.05}
{'loss': 0.7927, 'learning_rate': 4.994534068046937e-05, 'epoch': 0.05}
{'loss': 0.8013, 'learning_rate': 4.991461232516675e-05, 'epoch': 0.05}
{'loss': 0.7784, 'learning_rate': 4.9877072563625285e-05, 'epoch': 0.06}
{'loss': 0.7633, 'learning_rate': 4.9832731658840956e-05, 'epoch': 0.06}
{'loss': 0.7657, 'learning_rate': 4.978160173317438e-05, 'epoch': 0.07}
{'loss': 0.7547, 'learning_rate': 4.972369676503672e-05, 'epoch': 0.07}
{'loss': 0.7402, 'learning_rate': 4.965903258506806e-05, 'epoch': 0.07}
{'loss': 0.7372, 'learning_rate': 4.958762687180956e-05, 'epoch': 0.08}
{'loss': 0.7469, 'learning_rate': 4.9509499146870236e-05, 'epoch': 0.08}
{'loss': 0.7105, 'learning_rate': 4.9424670769589984e-05, 'epoch': 0.08}
{'loss': 0.7133, 'learning_rate': 4.933316493120015e-05, 'epoch': 0.09}
{'loss': 0.7261, 'learning_rate': 4.923500664848326e-05, 'epoch': 0.09}
{'loss': 0.7191, 'learning_rate': 4.913022275693372e-05, 'epoch': 0.09}
{'loss': 0.7207, 'learning_rate': 4.901884190342121e-05, 'epoch': 0.1}
{'loss': 0.7202, 'learning_rate': 4.8900894538358944e-05, 'epoch': 0.1}
{'loss': 0.707, 'learning_rate': 4.877641290737884e-05, 'epoch': 0.11}
{'loss': 0.7064, 'learning_rate': 4.864543104251587e-05, 'epoch': 0.11}
{'loss': 0.6963, 'learning_rate': 4.850798475290403e-05, 'epoch': 0.11}
{'loss': 0.7161, 'learning_rate': 4.8364111614986527e-05, 'epoch': 0.12}
{'loss': 0.7212, 'learning_rate': 4.821385096224268e-05, 'epoch': 0.12}
{'loss': 0.697, 'learning_rate': 4.805724387443462e-05, 'epoch': 0.12}
{'loss': 0.7019, 'learning_rate': 4.789433316637644e-05, 'epoch': 0.13}
{'loss': 0.7104, 'learning_rate': 4.7725163376229064e-05, 'epoch': 0.13}
{'loss': 0.6987, 'learning_rate': 4.754978075332398e-05, 'epoch': 0.13}
{'loss': 0.712, 'learning_rate': 4.736823324551909e-05, 'epoch': 0.14}
{'loss': 0.6841, 'learning_rate': 4.71805704860903e-05, 'epoch': 0.14}
{'loss': 0.6937, 'learning_rate': 4.698684378016222e-05, 'epoch': 0.15}
{'loss': 0.7054, 'learning_rate': 4.678710609068193e-05, 'epoch': 0.15}
{'loss': 0.6803, 'learning_rate': 4.6581412023939354e-05, 'epoch': 0.15}
{'loss': 0.6879, 'learning_rate': 4.6369817814638475e-05, 'epoch': 0.16}
{'loss': 0.6883, 'learning_rate': 4.6152381310523387e-05, 'epoch': 0.16}
{'loss': 0.6874, 'learning_rate': 4.592916195656322e-05, 'epoch': 0.16}
{'loss': 0.6713, 'learning_rate': 4.5700220778700504e-05, 'epoch': 0.17}
{'loss': 0.679, 'learning_rate': 4.546562036716732e-05, 'epoch': 0.17}
{'loss': 0.6683, 'learning_rate': 4.522542485937369e-05, 'epoch': 0.17}
{'loss': 0.682, 'learning_rate': 4.497969992237312e-05, 'epoch': 0.18}
{'loss': 0.6898, 'learning_rate': 4.4728512734909844e-05, 'epoch': 0.18}
{'loss': 0.6828, 'learning_rate': 4.4471931969052816e-05, 'epoch': 0.19}
{'loss': 0.6931, 'learning_rate': 4.421002777142148e-05, 'epoch': 0.19}
{'loss': 0.67, 'learning_rate': 4.3942871744008374e-05, 'epoch': 0.19}
{'loss': 0.6743, 'learning_rate': 4.367053692460385e-05, 'epoch': 0.2}
{'loss': 0.6778, 'learning_rate': 4.3393097766828293e-05, 'epoch': 0.2}
{'loss': 0.6759, 'learning_rate': 4.311063011977723e-05, 'epoch': 0.2}
{'loss': 0.6905, 'learning_rate': 4.282321120728493e-05, 'epoch': 0.21}
{'loss': 0.673, 'learning_rate': 4.2530919606812216e-05, 'epoch': 0.21}
{'loss': 0.6583, 'learning_rate': 4.223383522796415e-05, 'epoch': 0.21}
{'loss': 0.6507, 'learning_rate': 4.193203929064353e-05, 'epoch': 0.22}
{'loss': 0.6587, 'learning_rate': 4.16256143028462e-05, 'epoch': 0.22}
{'loss': 0.6761, 'learning_rate': 4.131464403810422e-05, 'epoch': 0.23}
{'loss': 0.6634, 'learning_rate': 4.099921351258292e-05, 'epoch': 0.23}
{'loss': 0.6583, 'learning_rate': 4.067940896183843e-05, 'epoch': 0.23}
{'loss': 0.6714, 'learning_rate': 4.03553178172417e-05, 'epoch': 0.24}
{'loss': 0.6815, 'learning_rate': 4.002702868207563e-05, 'epoch': 0.24}
{'loss': 0.6796, 'learning_rate': 3.969463130731183e-05, 'epoch': 0.24}
{'loss': 0.667, 'learning_rate': 3.935821656707359e-05, 'epoch': 0.25}
{'loss': 0.6662, 'learning_rate': 3.901787643379182e-05, 'epoch': 0.25}
{'loss': 0.6594, 'learning_rate': 3.867370395306068e-05, 'epoch': 0.25}
{'loss': 0.6901, 'learning_rate': 3.832579321819985e-05, 'epoch': 0.26}
{'loss': 0.6804, 'learning_rate': 3.797423934453038e-05, 'epoch': 0.26}
{'loss': 0.6639, 'learning_rate': 3.76191384433711e-05, 'epoch': 0.27}
{'loss': 0.667, 'learning_rate': 3.726058759576271e-05, 'epoch': 0.27}
{'loss': 0.6667, 'learning_rate': 3.689868482592684e-05, 'epoch': 0.27}
{'loss': 0.6743, 'learning_rate': 3.65335290744672e-05, 'epoch': 0.28}
{'loss': 0.6423, 'learning_rate': 3.616522017132017e-05, 'epoch': 0.28}
{'loss': 0.6802, 'learning_rate': 3.579385880846232e-05, 'epoch': 0.28}
{'loss': 0.6577, 'learning_rate': 3.5419546512382266e-05, 'epoch': 0.29}
{'loss': 0.6798, 'learning_rate': 3.504238561632424e-05, 'epoch': 0.29}
{'loss': 0.6522, 'learning_rate': 3.4662479232311306e-05, 'epoch': 0.29}
{'loss': 0.6735, 'learning_rate': 3.427993122295552e-05, 'epoch': 0.3}
{'loss': 0.6629, 'learning_rate': 3.389484617306292e-05, 'epoch': 0.3}
{'loss': 0.6652, 'learning_rate': 3.350732936104108e-05, 'epoch': 0.31}
{'loss': 0.6602, 'learning_rate': 3.311748673011709e-05, 'epoch': 0.31}
{'loss': 0.6639, 'learning_rate': 3.272542485937369e-05, 'epoch': 0.31}
{'loss': 0.6512, 'learning_rate': 3.2331250934611624e-05, 'epoch': 0.32}
{'loss': 0.658, 'learning_rate': 3.1935072719046115e-05, 'epoch': 0.32}
{'loss': 0.6781, 'learning_rate': 3.1536998523845494e-05, 'epoch': 0.32}
{'loss': 0.6745, 'learning_rate': 3.1137137178519985e-05, 'epoch': 0.33}
{'loss': 0.6563, 'learning_rate': 3.073559800116879e-05, 'epoch': 0.33}
{'loss': 0.6569, 'learning_rate': 3.0332490768593675e-05, 'epoch': 0.33}
{'loss': 0.6601, 'learning_rate': 2.9927925686287006e-05, 'epoch': 0.34}
{'loss': 0.6564, 'learning_rate': 2.952201335830275e-05, 'epoch': 0.34}
{'loss': 0.6373, 'learning_rate': 2.9114864757018352e-05, 'epoch': 0.35}
{'loss': 0.6501, 'learning_rate': 2.870659119279605e-05, 'epoch': 0.35}
{'loss': 0.6535, 'learning_rate': 2.8297304283551728e-05, 'epoch': 0.35}
{'loss': 0.6522, 'learning_rate': 2.788711592423966e-05, 'epoch': 0.36}
{'loss': 0.6662, 'learning_rate': 2.7476138256261575e-05, 'epoch': 0.36}
{'loss': 0.6619, 'learning_rate': 2.7064483636808313e-05, 'epoch': 0.36}
{'loss': 0.6576, 'learning_rate': 2.6652264608142484e-05, 'epoch': 0.37}
{'loss': 0.6511, 'learning_rate': 2.623959386683056e-05, 'epoch': 0.37}
{'loss': 0.6602, 'learning_rate': 2.5826584232932706e-05, 'epoch': 0.37}
{'loss': 0.6714, 'learning_rate': 2.5413348619158967e-05, 'epoch': 0.38}
{'loss': 0.666, 'learning_rate': 2.5e-05, 'epoch': 0.38}
{'loss': 0.6578, 'learning_rate': 2.458665138084104e-05, 'epoch': 0.38}
{'loss': 0.6594, 'learning_rate': 2.4173415767067297e-05, 'epoch': 0.39}
{'loss': 0.6551, 'learning_rate': 2.3760406133169443e-05, 'epoch': 0.39}
{'loss': 0.6569, 'learning_rate': 2.334773539185752e-05, 'epoch': 0.4}
{'loss': 0.6498, 'learning_rate': 2.2935516363191693e-05, 'epoch': 0.4}
{'loss': 0.6633, 'learning_rate': 2.2523861743738434e-05, 'epoch': 0.4}
{'loss': 0.6476, 'learning_rate': 2.2112884075760347e-05, 'epoch': 0.41}
{'loss': 0.6806, 'learning_rate': 2.1702695716448278e-05, 'epoch': 0.41}
{'loss': 0.6543, 'learning_rate': 2.1293408807203947e-05, 'epoch': 0.41}
{'loss': 0.6584, 'learning_rate': 2.088513524298165e-05, 'epoch': 0.42}
{'loss': 0.6485, 'learning_rate': 2.047798664169726e-05, 'epoch': 0.42}
{'loss': 0.6554, 'learning_rate': 2.0072074313712997e-05, 'epoch': 0.42}
{'loss': 0.6425, 'learning_rate': 1.9667509231406334e-05, 'epoch': 0.43}
{'loss': 0.6671, 'learning_rate': 1.9264401998831213e-05, 'epoch': 0.43}
{'loss': 0.6571, 'learning_rate': 1.8862862821480025e-05, 'epoch': 0.44}
{'loss': 0.651, 'learning_rate': 1.8463001476154508e-05, 'epoch': 0.44}
{'loss': 0.6656, 'learning_rate': 1.806492728095389e-05, 'epoch': 0.44}
{'loss': 0.6536, 'learning_rate': 1.7668749065388385e-05, 'epoch': 0.45}
{'loss': 0.6666, 'learning_rate': 1.7274575140626318e-05, 'epoch': 0.45}
{'loss': 0.6515, 'learning_rate': 1.6882513269882917e-05, 'epoch': 0.45}
{'loss': 0.6461, 'learning_rate': 1.6492670638958924e-05, 'epoch': 0.46}
{'loss': 0.6341, 'learning_rate': 1.6105153826937085e-05, 'epoch': 0.46}
{'loss': 0.6354, 'learning_rate': 1.5720068777044476e-05, 'epoch': 0.46}
{'loss': 0.6631, 'learning_rate': 1.5337520767688703e-05, 'epoch': 0.47}
{'loss': 0.6608, 'learning_rate': 1.495761438367577e-05, 'epoch': 0.47}
{'loss': 0.6468, 'learning_rate': 1.4580453487617745e-05, 'epoch': 0.48}
{'loss': 0.6354, 'learning_rate': 1.4206141191537682e-05, 'epoch': 0.48}
{'loss': 0.6489, 'learning_rate': 1.383477982867984e-05, 'epoch': 0.48}
{'loss': 0.6279, 'learning_rate': 1.346647092553281e-05, 'epoch': 0.49}
{'loss': 0.6341, 'learning_rate': 1.3101315174073162e-05, 'epoch': 0.49}
{'loss': 0.6489, 'learning_rate': 1.2739412404237306e-05, 'epoch': 0.49}
{'loss': 0.6686, 'learning_rate': 1.2380861556628915e-05, 'epoch': 0.5}
{'loss': 0.637, 'learning_rate': 1.202576065546963e-05, 'epoch': 0.5}
{'loss': 0.6539, 'learning_rate': 1.1674206781800162e-05, 'epoch': 0.5}
{'loss': 0.667, 'learning_rate': 1.1326296046939333e-05, 'epoch': 0.51}
{'loss': 0.653, 'learning_rate': 1.0982123566208185e-05, 'epoch': 0.51}
{'loss': 0.6556, 'learning_rate': 1.064178343292641e-05, 'epoch': 0.52}
{'loss': 0.6602, 'learning_rate': 1.0305368692688174e-05, 'epoch': 0.52}
{'loss': 0.6517, 'learning_rate': 9.972971317924374e-06, 'epoch': 0.52}
{'loss': 0.6524, 'learning_rate': 9.644682182758306e-06, 'epoch': 0.53}
{'loss': 0.6436, 'learning_rate': 9.320591038161574e-06, 'epoch': 0.53}
{'loss': 0.6525, 'learning_rate': 9.000786487417085e-06, 'epoch': 0.53}
{'loss': 0.6434, 'learning_rate': 8.685355961895784e-06, 'epoch': 0.54}
{'loss': 0.6515, 'learning_rate': 8.374385697153792e-06, 'epoch': 0.54}
{'loss': 0.6654, 'learning_rate': 8.067960709356478e-06, 'epoch': 0.54}
{'loss': 0.6411, 'learning_rate': 7.766164772035856e-06, 'epoch': 0.55}
{'loss': 0.6445, 'learning_rate': 7.469080393187786e-06, 'epoch': 0.55}
{'loss': 0.6446, 'learning_rate': 7.176788792715075e-06, 'epoch': 0.56}
{'loss': 0.6531, 'learning_rate': 6.889369880222776e-06, 'epoch': 0.56}
{'loss': 0.6668, 'learning_rate': 6.606902233171711e-06, 'epoch': 0.56}
{'loss': 0.636, 'learning_rate': 6.329463075396161e-06, 'epoch': 0.57}
{'loss': 0.6668, 'learning_rate': 6.057128255991637e-06, 'epoch': 0.57}
{'loss': 0.6411, 'learning_rate': 5.78997222857853e-06, 'epoch': 0.57}
{'loss': 0.633, 'learning_rate': 5.528068030947192e-06, 'epoch': 0.58}
{'loss': 0.6571, 'learning_rate': 5.271487265090163e-06, 'epoch': 0.58}
{'loss': 0.654, 'learning_rate': 5.0203000776268825e-06, 'epoch': 0.58}
{'loss': 0.6607, 'learning_rate': 4.7745751406263165e-06, 'epoch': 0.59}
{'loss': 0.6767, 'learning_rate': 4.534379632832692e-06, 'epoch': 0.59}
{'loss': 0.6416, 'learning_rate': 4.299779221299499e-06, 'epoch': 0.6}
{'loss': 0.6363, 'learning_rate': 4.070838043436786e-06, 'epoch': 0.6}
{'loss': 0.6667, 'learning_rate': 3.847618689476612e-06, 'epoch': 0.6}
{'loss': 0.6381, 'learning_rate': 3.630182185361522e-06, 'epoch': 0.61}
{'loss': 0.6574, 'learning_rate': 3.418587976060653e-06, 'epoch': 0.61}
{'loss': 0.6406, 'learning_rate': 3.2128939093180655e-06, 'epoch': 0.61}
{'loss': 0.6387, 'learning_rate': 3.013156219837776e-06, 'epoch': 0.62}
{'loss': 0.6594, 'learning_rate': 2.8194295139097048e-06, 'epoch': 0.62}
{'loss': 0.6481, 'learning_rate': 2.6317667544809134e-06, 'epoch': 0.62}
{'loss': 0.6412, 'learning_rate': 2.4502192466760276e-06, 'epoch': 0.63}
{'loss': 0.6669, 'learning_rate': 2.2748366237709374e-06, 'epoch': 0.63}
{'loss': 0.6394, 'learning_rate': 2.1056668336235622e-06, 'epoch': 0.64}
{'loss': 0.6387, 'learning_rate': 1.9427561255653816e-06, 'epoch': 0.64}
{'loss': 0.6383, 'learning_rate': 1.7861490377573258e-06, 'epoch': 0.64}
{'loss': 0.6471, 'learning_rate': 1.6358883850134816e-06, 'epoch': 0.65}
{'loss': 0.6429, 'learning_rate': 1.4920152470959707e-06, 'epoch': 0.65}
{'loss': 0.6478, 'learning_rate': 1.3545689574841342e-06, 'epoch': 0.65}
{'loss': 0.6526, 'learning_rate': 1.2235870926211619e-06, 'epoch': 0.66}
{'loss': 0.6499, 'learning_rate': 1.0991054616410589e-06, 'epoch': 0.66}
{'loss': 0.6389, 'learning_rate': 9.811580965787965e-07, 'epoch': 0.66}
{'loss': 0.622, 'learning_rate': 8.697772430662859e-07, 'epoch': 0.67}
{'loss': 0.6537, 'learning_rate': 7.649933515167407e-07, 'epoch': 0.67}
{'loss': 0.6477, 'learning_rate': 6.668350687998565e-07, 'epoch': 0.68}
{'loss': 0.6467, 'learning_rate': 5.753292304100183e-07, 'epoch': 0.68}
{'loss': 0.6401, 'learning_rate': 4.905008531297661e-07, 'epoch': 0.68}
{'loss': 0.6553, 'learning_rate': 4.1237312819044085e-07, 'epoch': 0.69}
{'loss': 0.6565, 'learning_rate': 3.4096741493194197e-07, 'epoch': 0.69}
{'loss': 0.6495, 'learning_rate': 2.763032349632877e-07, 'epoch': 0.69}
{'loss': 0.6375, 'learning_rate': 2.1839826682562015e-07, 'epoch': 0.7}
{'loss': 0.6499, 'learning_rate': 1.6726834115904643e-07, 'epoch': 0.7}
{'loss': 0.6514, 'learning_rate': 1.229274363747146e-07, 'epoch': 0.7}
{'loss': 0.6461, 'learning_rate': 8.538767483325383e-08, 'epoch': 0.71}
{'loss': 0.6613, 'learning_rate': 5.4659319530636633e-08, 'epoch': 0.71}
{'loss': 0.656, 'learning_rate': 3.075077129238158e-08, 'epoch': 0.72}
{'loss': 0.6393, 'learning_rate': 1.3668566476848777e-08, 'epoch': 0.72}
{'loss': 0.6647, 'learning_rate': 3.417375188274896e-09, 'epoch': 0.72}
{'loss': 0.6562, 'learning_rate': 0.0, 'epoch': 0.73}
{'train_runtime': 10624.758, 'train_samples_per_second': 3.012, 'train_steps_per_second': 0.094, 'train_loss': 0.6977045402526856, 'epoch': 0.73}
***** train metrics *****
  epoch                    =       0.73
  train_loss               =     0.6977
  train_runtime            = 2:57:04.75
  train_samples            =      44056
  train_samples_per_second =      3.012
  train_steps_per_second   =      0.094

========== MODEL STRUCTURE ==========
PeftModelForCausalLM(
  (base_model): MoELoraModel(
    (model): LlamaForCausalLM(
      (model): LlamaModel(
        (embed_tokens): Embedding(128256, 4096)
        (layers): ModuleList(
          (0-31): 32 x LlamaDecoderLayer(
            (self_attn): LlamaSdpaAttention(
              (q_proj): MoELinear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): Dropout(p=0.05, inplace=False)
                (lora_route): Linear(in_features=4096, out_features=4, bias=False)
                (lora_As): ModuleList(
                  (0-3): 4 x Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_Bs): ModuleList(
                  (0-3): 4 x Linear(in_features=8, out_features=4096, bias=False)
                )
              )
              (k_proj): MoELinear(
                in_features=4096, out_features=1024, bias=False
                (lora_dropout): Dropout(p=0.05, inplace=False)
                (lora_route): Linear(in_features=4096, out_features=4, bias=False)
                (lora_As): ModuleList(
                  (0-3): 4 x Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_Bs): ModuleList(
                  (0-3): 4 x Linear(in_features=8, out_features=1024, bias=False)
                )
              )
              (v_proj): MoELinear(
                in_features=4096, out_features=1024, bias=False
                (lora_dropout): Dropout(p=0.05, inplace=False)
                (lora_route): Linear(in_features=4096, out_features=4, bias=False)
                (lora_As): ModuleList(
                  (0-3): 4 x Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_Bs): ModuleList(
                  (0-3): 4 x Linear(in_features=8, out_features=1024, bias=False)
                )
              )
              (o_proj): MoELinear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): Dropout(p=0.05, inplace=False)
                (lora_route): Linear(in_features=4096, out_features=4, bias=False)
                (lora_As): ModuleList(
                  (0-3): 4 x Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_Bs): ModuleList(
                  (0-3): 4 x Linear(in_features=8, out_features=4096, bias=False)
                )
              )
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
              (act_fn): SiLU()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
      )
      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)
    )
  )
)

========== TRAINABLE PARAMETERS ==========
base_model.model.model.layers.0.self_attn.q_proj.lora_route.weight: shape=torch.Size([4, 4096]), numel=16384
base_model.model.model.layers.0.self_attn.q_proj.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.q_proj.lora_As.1.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.q_proj.lora_As.2.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.q_proj.lora_As.3.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.q_proj.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.0.self_attn.q_proj.lora_Bs.1.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.0.self_attn.q_proj.lora_Bs.2.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.0.self_attn.q_proj.lora_Bs.3.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.0.self_attn.k_proj.lora_route.weight: shape=torch.Size([4, 4096]), numel=16384
base_model.model.model.layers.0.self_attn.k_proj.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.k_proj.lora_As.1.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.k_proj.lora_As.2.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.k_proj.lora_As.3.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.k_proj.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.0.self_attn.k_proj.lora_Bs.1.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.0.self_attn.k_proj.lora_Bs.2.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.0.self_attn.k_proj.lora_Bs.3.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.0.self_attn.v_proj.lora_route.weight: shape=torch.Size([4, 4096]), numel=16384
base_model.model.model.layers.0.self_attn.v_proj.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.v_proj.lora_As.1.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.v_proj.lora_As.2.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.v_proj.lora_As.3.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.v_proj.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.0.self_attn.v_proj.lora_Bs.1.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.0.self_attn.v_proj.lora_Bs.2.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.0.self_attn.v_proj.lora_Bs.3.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.0.self_attn.o_proj.lora_route.weight: shape=torch.Size([4, 4096]), numel=16384
base_model.model.model.layers.0.self_attn.o_proj.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.o_proj.lora_As.1.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.o_proj.lora_As.2.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.o_proj.lora_As.3.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.o_proj.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.0.self_attn.o_proj.lora_Bs.1.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.0.self_attn.o_proj.lora_Bs.2.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.0.self_attn.o_proj.lora_Bs.3.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.1.self_attn.q_proj.lora_route.weight: shape=torch.Size([4, 4096]), numel=16384
base_model.model.model.layers.1.self_attn.q_proj.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.1.self_attn.q_proj.lora_As.1.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.1.self_attn.q_proj.lora_As.2.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.1.self_attn.q_proj.lora_As.3.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.1.self_attn.q_proj.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.1.self_attn.q_proj.lora_Bs.1.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.1.self_attn.q_proj.lora_Bs.2.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.1.self_attn.q_proj.lora_Bs.3.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.1.self_attn.k_proj.lora_route.weight: shape=torch.Size([4, 4096]), numel=16384
base_model.model.model.layers.1.self_attn.k_proj.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.1.self_attn.k_proj.lora_As.1.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.1.self_attn.k_proj.lora_As.2.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.1.self_attn.k_proj.lora_As.3.weight: shape=torch.Size([8, 4096]), numel=32768

Total trainable parameters: 29,360,128 / 8,059,621,376 (0.36%)

========== MODEL STRUCTURE ==========
PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): LlamaForCausalLM(
      (model): LlamaModel(
        (embed_tokens): Embedding(128256, 4096)
        (layers): ModuleList(
          (0-31): 32 x LlamaDecoderLayer(
            (self_attn): LlamaSdpaAttention(
              (q_proj): lora.Linear(
                (base_layer): MoELinear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_route): None
                  (lora_As): ModuleList(
                    (0): Linear(in_features=4096, out_features=8, bias=False)
                  )
                  (lora_Bs): ModuleList(
                    (0): Linear(in_features=8, out_features=4096, bias=False)
                  )
                )
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=8, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (k_proj): lora.Linear(
                (base_layer): MoELinear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_route): None
                  (lora_As): ModuleList(
                    (0): Linear(in_features=4096, out_features=8, bias=False)
                  )
                  (lora_Bs): ModuleList(
                    (0): Linear(in_features=8, out_features=1024, bias=False)
                  )
                )
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=8, out_features=1024, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (v_proj): lora.Linear(
                (base_layer): MoELinear(
                  in_features=4096, out_features=1024, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_route): None
                  (lora_As): ModuleList(
                    (0): Linear(in_features=4096, out_features=8, bias=False)
                  )
                  (lora_Bs): ModuleList(
                    (0): Linear(in_features=8, out_features=1024, bias=False)
                  )
                )
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=8, out_features=1024, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (o_proj): lora.Linear(
                (base_layer): MoELinear(
                  in_features=4096, out_features=4096, bias=False
                  (lora_dropout): Dropout(p=0.05, inplace=False)
                  (lora_route): None
                  (lora_As): ModuleList(
                    (0): Linear(in_features=4096, out_features=8, bias=False)
                  )
                  (lora_Bs): ModuleList(
                    (0): Linear(in_features=8, out_features=4096, bias=False)
                  )
                )
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=8, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
              (act_fn): SiLU()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
      )
      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)
    )
  )
)

========== TRAINABLE PARAMETERS ==========
base_model.model.model.layers.0.self_attn.q_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.q_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.0.self_attn.k_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.k_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.0.self_attn.v_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.v_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.0.self_attn.o_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.0.self_attn.o_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.1.self_attn.q_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.1.self_attn.q_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.1.self_attn.k_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.1.self_attn.k_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.1.self_attn.v_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.1.self_attn.v_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.1.self_attn.o_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.1.self_attn.o_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.2.self_attn.q_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.2.self_attn.q_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.2.self_attn.k_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.2.self_attn.k_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.2.self_attn.v_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.2.self_attn.v_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.2.self_attn.o_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.2.self_attn.o_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.3.self_attn.q_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.3.self_attn.q_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.3.self_attn.k_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.3.self_attn.k_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.3.self_attn.v_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.3.self_attn.v_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.3.self_attn.o_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.3.self_attn.o_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.4.self_attn.q_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.4.self_attn.q_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.4.self_attn.k_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.4.self_attn.k_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.4.self_attn.v_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.4.self_attn.v_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.4.self_attn.o_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.4.self_attn.o_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.5.self_attn.q_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.5.self_attn.q_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.5.self_attn.k_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.5.self_attn.k_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.5.self_attn.v_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.5.self_attn.v_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([1024, 8]), numel=8192
base_model.model.model.layers.5.self_attn.o_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.5.self_attn.o_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768
base_model.model.model.layers.6.self_attn.q_proj.base_layer.lora_As.0.weight: shape=torch.Size([8, 4096]), numel=32768
base_model.model.model.layers.6.self_attn.q_proj.base_layer.lora_Bs.0.weight: shape=torch.Size([4096, 8]), numel=32768

Total trainable parameters: 6,815,744 / 8,043,892,736 (0.08%)
/root/miniconda3/lib/python3.10/site-packages/transformers/utils/hub.py:821: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
adapter_model.safetensors: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 27.3M/27.3M [00:03<00:00, 8.55MB/s]
