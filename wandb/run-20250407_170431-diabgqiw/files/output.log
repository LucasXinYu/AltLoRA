100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f43de6-303b2c5f211be5c83b7439f2;6277e7f7-55f1-410c-9391-360e092227a9)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
{'train_runtime': 8.07, 'train_samples_per_second': 0.124, 'train_steps_per_second': 0.124, 'train_loss': 0.43780967593193054, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               =    16407GF
  train_loss               =     0.4378
  train_runtime            = 0:00:08.07
  train_samples            =         11
  train_samples_per_second =      0.124
  train_steps_per_second   =      0.124
0
1.2e-06
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.43it/s]
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f43de8-3566eb632d82f3a076a4c934;ae62cbf8-0d6b-4c83-80a9-2ae604c6eb43)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
  0%|                                                                                                                    | 0/1 [00:00<?, ?it/s]
{'train_runtime': 0.4369, 'train_samples_per_second': 2.289, 'train_steps_per_second': 2.289, 'train_loss': 0.4038405120372772, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               =    16407GF
  train_loss               =     0.4038
  train_runtime            = 0:00:00.43
  train_samples            =         12
  train_samples_per_second =      2.289
  train_steps_per_second   =      2.289
0
1.2e-06
{'train_runtime': 0.4358, 'train_samples_per_second': 2.294, 'train_steps_per_second': 2.294, 'train_loss': 0.3567880392074585, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               =    16407GF
  train_loss               =     0.3568
  train_runtime            = 0:00:00.43
  train_samples            =         11
  train_samples_per_second =      2.294
  train_steps_per_second   =      2.294
0
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f43de9-60b8e8377ea2b0ae32809fc1;c66e1a7f-83bb-40ce-84a7-dee284557c63)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.49it/s]
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f43dea-2bd222a31d2a8d11349c5133;f5724765-58bc-4926-a89a-8ea95dde15b4)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(
{'train_runtime': 0.426, 'train_samples_per_second': 2.347, 'train_steps_per_second': 2.347, 'train_loss': 0.4171334207057953, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               =    16407GF
  train_loss               =     0.4171
  train_runtime            = 0:00:00.42
  train_samples            =         11
  train_samples_per_second =      2.347
  train_steps_per_second   =      2.347
0
1.2e-06
{'train_runtime': 0.4332, 'train_samples_per_second': 2.308, 'train_steps_per_second': 2.308, 'train_loss': 0.4248386323451996, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               =    16407GF
  train_loss               =     0.4248
  train_runtime            = 0:00:00.43
  train_samples            =         11
  train_samples_per_second =      2.308
  train_steps_per_second   =      2.308
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.45it/s]
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error 403 Client Error. (Request ID: Root=1-67f43dec-2eb73d1b217678171a98d900;a74ec165-3278-4d9e-bb90-18fdfe480ff4)
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.
Access to model meta-llama/Llama-3.2-3B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B to ask for access. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.
  warnings.warn(
/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.
  warnings.warn(












  File "/data/home/yjw5427/translora/fed_lora.py", line 936, in <module>███████████████████████████████████████| 32/32 [00:23<00:00,  1.60it/s]
    main()
  File "/data/home/yjw5427/translora/fed_lora.py", line 830, in main
    metrics = trainer.evaluate()
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/trainer.py", line 3868, in evaluate
    output = eval_loop(
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/trainer.py", line 4160, in evaluation_loop
    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))
  File "/data/home/yjw5427/translora/fed_lora.py", line 700, in compute_metrics
    accuracy_result = metric.compute(predictions=processed_preds, references=processed_labels)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/evaluate/module.py", line 432, in compute
    self.add_batch(**inputs)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/evaluate/module.py", line 486, in add_batch
    batch = self.selected_feature_format.encode_batch(batch)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/datasets/features/features.py", line 1958, in encode_batch
    encoded_batch[key] = [encode_nested_example(self[key], obj, level=1) for obj in column]
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/datasets/features/features.py", line 1958, in <listcomp>
    encoded_batch[key] = [encode_nested_example(self[key], obj, level=1) for obj in column]
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/datasets/features/features.py", line 1300, in encode_nested_example
    return schema.encode_example(obj) if obj is not None else None
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/datasets/features/features.py", line 515, in encode_example
    return int(value)
ValueError: invalid literal for int() with base 10: 'None'
Traceback (most recent call last):
  File "/data/home/yjw5427/translora/fed_lora.py", line 936, in <module>
    main()
  File "/data/home/yjw5427/translora/fed_lora.py", line 830, in main
    metrics = trainer.evaluate()
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/trainer.py", line 3868, in evaluate
    output = eval_loop(
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/trainer.py", line 4160, in evaluation_loop
    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))
  File "/data/home/yjw5427/translora/fed_lora.py", line 700, in compute_metrics
    accuracy_result = metric.compute(predictions=processed_preds, references=processed_labels)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/evaluate/module.py", line 432, in compute
    self.add_batch(**inputs)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/evaluate/module.py", line 486, in add_batch
    batch = self.selected_feature_format.encode_batch(batch)
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/datasets/features/features.py", line 1958, in encode_batch
    encoded_batch[key] = [encode_nested_example(self[key], obj, level=1) for obj in column]
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/datasets/features/features.py", line 1958, in <listcomp>
    encoded_batch[key] = [encode_nested_example(self[key], obj, level=1) for obj in column]
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/datasets/features/features.py", line 1300, in encode_nested_example
    return schema.encode_example(obj) if obj is not None else None
  File "/home/yjw5427/miniconda3/envs/trans/lib/python3.10/site-packages/datasets/features/features.py", line 515, in encode_example
    return int(value)
ValueError: invalid literal for int() with base 10: 'None'
Evaluation Samples:
Sample 1: Prediction: None, Label: None
Sample 2: Prediction: None, Label: None
Sample 3: Prediction: None, Label: None
Sample 4: Prediction: None, Label: None
Sample 5: Prediction: None, Label: None